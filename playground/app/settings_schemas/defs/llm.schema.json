{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "schema://settings/defs/llm",
  "title": "LLM Settings (Prompt Budget)",
  "description": "LLM settings that influence prompt budgeting and trimming.",
  "$defs": {
    "GenerationSettings": {
      "type": "object",
      "additionalProperties": false,
      "default": {},
      "x-ui": {
        "label": "Generation",
        "control": "group",
        "quick": true,
        "order": 10
      },
      "properties": {
        "max_context_tokens": {
          "type": "integer",
          "default": 8192,
          "minimum": 256,
          "maximum": 200000,
          "x-ui": {
            "label": "Max Context (tokens)",
            "control": "number",
            "quick": true,
            "order": 1
          },
          "description": "Context window token limit used for prompt trimming."
        },
        "max_response_tokens": {
          "type": "integer",
          "default": 512,
          "minimum": 1,
          "maximum": 8192,
          "x-ui": {
            "label": "Reserved Response (tokens)",
            "control": "number",
            "quick": true,
            "order": 2
          },
          "description": "Reserved tokens for the model's response (reduces available prompt budget)."
        },
        "temperature": {
          "type": "number",
          "default": 1.0,
          "minimum": 0,
          "maximum": 2,
          "x-ui": {
            "label": "Temperature",
            "control": "slider",
            "quick": true,
            "order": 3,
            "range": {
              "min": 0,
              "max": 2,
              "step": 0.01
            }
          },
          "description": "Controls randomness in generation. Lower values make output more focused and deterministic."
        },
        "top_p": {
          "type": "number",
          "default": 1.0,
          "minimum": 0,
          "maximum": 1,
          "x-ui": {
            "label": "Top P",
            "control": "slider",
            "quick": true,
            "order": 4,
            "range": {
              "min": 0,
              "max": 1,
              "step": 0.01
            }
          },
          "description": "Nucleus sampling threshold. Only tokens with cumulative probability up to this value are considered."
        },
        "top_k": {
          "type": "integer",
          "default": 0,
          "minimum": 0,
          "maximum": 100,
          "x-ui": {
            "label": "Top K",
            "control": "number",
            "quick": false,
            "order": 5
          },
          "description": "Limits sampling to the top K most likely tokens. 0 means no limit."
        },
        "repetition_penalty": {
          "type": "number",
          "default": 1.0,
          "minimum": 1,
          "maximum": 2,
          "x-ui": {
            "label": "Repetition Penalty",
            "control": "slider",
            "quick": false,
            "order": 6,
            "range": {
              "min": 1,
              "max": 2,
              "step": 0.01
            }
          },
          "description": "Penalizes repeated tokens. Values above 1.0 reduce repetition."
        }
      },
      "description": "Generation"
    }
  }
}
